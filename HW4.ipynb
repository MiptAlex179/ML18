{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt\">MIPT, Applied ML, Autumn 2018</span>\n",
    "\n",
    "<span style=\"font-size: 16pt\"> HW #4: Approximate RL homework\n",
    "\n",
    "<span style=\"color:red; font-size: 14pt;\"> Дедлайн 19.11.2018 23:59 </span>\n",
    "\n",
    "<span style=\"color:blue; font-size: 12pt\">Valentin Malykh </span>,\n",
    "<span style=\"color:blue; font-size: 12pt; font-family: 'Verdana'\">val@maly.hk</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Оформление дз**: \n",
    "- Выполненное задание требуется отправлять через <a href='https://goo.gl/forms/XPSIbwp7wPxB4SsI3'>форму </a>\n",
    "\n",
    "- Выполненное дз прикрепляйте в формате файла ``<фамилия>_<группа>_task<номер>.ipynb``, например: ``ivanov_594_task4.ipynb`` \n",
    "\n",
    "**Вопросы**:\n",
    "- Вопросы присылайте в канал в телеграмме ``[Fall 2018]ML Seminars``\n",
    "\n",
    "--------\n",
    "- **PS1**: Будьте внимательны при заполнении формы, когда отправляете ДЗ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Практическое задание (100%)</h1>\n",
    "Описание находится по ссылке: https://gist.github.com/madrugado/1262c3077bf7d8ac8166e4350f0f67e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-11-16 15:10:28,735] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(s, a, p):\n",
    "    return model.predict(np.concatenate((s, np.eye(4)[a], p), axis=0).reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(s, a):\n",
    "    return model.predict(np.concatenate((s, np.eye(4)[a]), axis=0).reshape(1, -1))[0][0]\n",
    "\n",
    "def use_prob(episode):\n",
    "    return 0.05*(1 - episode/num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузить модель, обученную на 10000 эпизодах\n",
    "model = keras.models.load_model(\"imodel10ktr.mdh5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузить модель, обученную на 50000 эпизодах - дает наилучшие результаты\n",
    "model = keras.models.load_model(\"model50k.mdh5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузить модель, обученную на 100000 эпизодах и учетом луны\n",
    "model = keras.models.load_model(\"i512model100ktr.mdh5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучить новую модель\n",
    "\n",
    "dimX = 8 + 4\n",
    "num_episodes = 10000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=dimX))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer=optimizers.adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "dataX = np.zeros(shape=(1, dimX))\n",
    "dataY = np.zeros(shape=(1, 1))\n",
    "\n",
    "over_ind = 0\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    e_dataX = np.zeros(shape=(1, dimX))\n",
    "    e_dataY = np.zeros(shape=(1, 1))\n",
    "    \n",
    "    s = env.reset()\n",
    "    total_r = 0\n",
    "    First = True\n",
    "    \n",
    "    while True:\n",
    "        if episode % 100 == 0:\n",
    "            env.render()\n",
    "        \n",
    "        if np.random.rand(1) < use_prob(episode):\n",
    "            a=env.action_space.sample()\n",
    "        else:\n",
    "            a = np.argmax(np.array([Q(s, 0), Q(s, 1), Q(s, 2), Q(s, 3)]))\n",
    "\n",
    "        string = np.concatenate((s, np.eye(4)[a]), axis=0)\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "\n",
    "        if First:\n",
    "            e_dataX[0] = string\n",
    "            e_dataY[0] = np.array([r])\n",
    "            dataX[0] = string\n",
    "            dataY[0] = np.array([r])\n",
    "            First = False\n",
    "\n",
    "        e_dataX = np.vstack((e_dataX, string))\n",
    "        e_dataY = np.vstack((e_dataY, np.array([r])))\n",
    "\n",
    "        total_r += r\n",
    "\n",
    "        s = new_s\n",
    "        \n",
    "        if done:\n",
    "#             if total_r >= 200:\n",
    "#                 r = 1000\n",
    "            n = len(e_dataY)\n",
    "            for i in range(1, n):\n",
    "                e_dataY[n - i - 1][0] = e_dataY[n - i - 1][0] + 0.98 * e_dataY[n - i][0]\n",
    "            \n",
    "            print(\"Episode №\", episode, \" last reward = \", r, \", total reward = \", total_r)\n",
    "\n",
    "            if len(dataX) == 1:\n",
    "                dataX = e_dataX\n",
    "                dataY = e_dataY\n",
    "            else:\n",
    "                dataX = np.concatenate((dataX, e_dataX), axis=0)\n",
    "                dataY = np.concatenate((dataY, e_dataY), axis=0)\n",
    "\n",
    "            if len(dataX) > 60000:\n",
    "                dataX = np.delete(dataX, range(over_ind, over_ind + len(e_dataX)), axis=0)\n",
    "                dataY = np.delete(dataY, range(over_ind, over_ind + len(e_dataX)), axis=0)\n",
    "                over_ind += len(e_dataX)\n",
    "                if over_ind > 59800:\n",
    "                    over_ind = 0\n",
    "\n",
    "            if episode%10 == 0:\n",
    "                model.fit(dataX, dataY, batch_size=32, epochs=2, verbose=0)\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_n_episodes(n, rend = False):\n",
    "    wins_cnt = 0\n",
    "    for episode in range(n):\n",
    "        s = env.reset()\n",
    "        total_r = 0\n",
    "        while True:\n",
    "#             env.render()\n",
    "            a = np.argmax(np.array([Q(s, 0), Q(s, 1), Q(s, 2), Q(s, 3)]))\n",
    "            new_s, r, done, info = env.step(a)\n",
    "            total_r += r\n",
    "            s = new_s\n",
    "            if done:\n",
    "                if total_r >= 200:\n",
    "                    print(\"total reward - \" + str(total_r) + \", WIN\")\n",
    "                    wins_cnt += 1\n",
    "                else:\n",
    "                    print(\"total reward - \" + str(total_r) + \", LOSE\")\n",
    "                break\n",
    "    print(\"Wins \" + str(wins_cnt) + \" of \" + str(n) + \" episodes.\")\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total reward - 215.90487014632544, WIN\n",
      "total reward - 228.99222923197436, WIN\n",
      "total reward - 235.4016250849651, WIN\n",
      "total reward - 221.47740988970259, WIN\n",
      "total reward - 212.72065215700349, WIN\n",
      "total reward - 218.18788523129857, WIN\n",
      "total reward - 204.07505536510232, WIN\n",
      "total reward - 216.23714528085668, WIN\n",
      "total reward - 226.82981262472754, WIN\n",
      "total reward - 262.94399702637804, WIN\n",
      "Wins 10 of 10 episodes.\n"
     ]
    }
   ],
   "source": [
    "play_n_episodes(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
